{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96716172-e110-4e14-abd9-2ec9fcd99a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6143bc55-86ce-4d92-ad76-f40ace104c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the current SageMaker session\n",
    "session = sagemaker.Session()\n",
    "# Define the global bucket name\n",
    "bucket = \"data14group1-ml\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23aa68f7-72de-4421-b57d-614dcb2fb73c",
   "metadata": {},
   "source": [
    "### Download trainval data parquet files from S3 bucket "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c188eab-97d1-4c2c-94cb-0143f98e16c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Boto3 client\n",
    "s3_client = boto3.client('s3')\n",
    "\n",
    "# Define S3 bucket and folder path\n",
    "bucket_name = \"data14group1-ml\"\n",
    "s3_folder_path = 'data/trainval/'\n",
    "\n",
    "# Define the local directory where files will be downloaded\n",
    "local_dir = \"data/\"\n",
    "\n",
    "# Ensure the local directory exists\n",
    "if not os.path.exists(local_dir):\n",
    "    os.makedirs(local_dir)\n",
    "\n",
    "# List all objects in the S3 folder\n",
    "response = s3_client.list_objects_v2(Bucket=bucket_name, Prefix=s3_folder_path)\n",
    "\n",
    "# Iterate through the objects and download each one\n",
    "for obj in response.get('Contents', []):\n",
    "    # Get the file path\n",
    "    s3_file_path = obj['Key']\n",
    "    file_name = os.path.basename(s3_file_path)\n",
    "\n",
    "    # Define the local file path\n",
    "    local_file_path = os.path.join(local_dir, file_name)\n",
    "\n",
    "    # Download the file from S3\n",
    "    s3_client.download_file(bucket_name, s3_file_path, local_file_path)\n",
    "    print(f'Downloaded {s3_file_path} to {local_file_path}')\n",
    "\n",
    "print(\"\\ndata download complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380d9f9-f150-4e45-9b67-cbb65befea91",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Split data into train, valuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879fdbf8-3883-4f3c-b5ba-4585b4a225af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"ReadParquetFromS3\").getOrCreate()\n",
    "\n",
    "# Define file path\n",
    "file_path = f\"data/\"\n",
    "\n",
    "# Read the Parquet file into a DataFrame\n",
    "data = spark.read.parquet(file_path)\n",
    "\n",
    "print(\"data loading complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8883888f-8f71-41ed-8463-3233d47e9f15",
   "metadata": {},
   "source": [
    "### Check data integrity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75befb74-3b92-40bc-b182-d59d80f5c655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill the NaN with zero\n",
    "data.fillna(0)\n",
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c322d0-4329-4169-876f-0b62b8e76bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (80%) and validation (20%) sets\n",
    "seed = 42\n",
    "train, validation = data.randomSplit([0.8,0.2], seed=seed)\n",
    "print(\"train and validation sets are randomly selected\")\n",
    "\n",
    "print(train.count())\n",
    "print(validation.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75896524-2481-4f4d-a9d2-4c83585fdc6d",
   "metadata": {},
   "source": [
    "### Save train and validation sets to local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a3d249-fb29-4350-bb20-8cecb34649f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train/\"\n",
    "train.write.mode(\"overwrite\").parquet(file_path)\n",
    "print(\"train file saving complete\")\n",
    "\n",
    "file_path = \"validation/\"\n",
    "validation.write.mode(\"overwrite\").parquet(file_path)\n",
    "print(\"validation file saving complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42cf374-b336-41cc-8902-0c4b79a7ad56",
   "metadata": {},
   "source": [
    "### Save train and validation sets to local folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d026f8b2-3ef0-47e2-b6d4-8d615cd1b955",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"train/\"\n",
    "train.write.mode(\"overwrite\").parquet(file_path)\n",
    "print(\"train file saving complete\")\n",
    "\n",
    "file_path = \"validation/\"\n",
    "validation.write.mode(\"overwrite\").parquet(file_path)\n",
    "print(\"validation file saving complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea44f02-f208-4457-9d5d-32c26df3c88b",
   "metadata": {},
   "source": [
    "### Upload to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9461120-db01-4a38-92a9-3c6afcfa2a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make sure delete hidden files in the train and validation folder in S3 before training\n",
    "\n",
    "Model training won't work if we don't delete them!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e2b8d3-63c4-45d3-a713-5ba7dc22a423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify your bucket name\n",
    "bucket = \"data14group1-ml\"\n",
    "prefix_train = \"data/train\"  # Optional: specify if you want to delete within a specific prefix\n",
    "prefix_validation = \"data/validation\"\n",
    "\n",
    "def delete_crc(bucket_name, prefix):\n",
    "    # List and delete .crc files\n",
    "    paginator = s3_client.get_paginator('list_objects_v2')\n",
    "    for page in paginator.paginate(Bucket=bucket_name, Prefix=prefix):\n",
    "        for obj in page.get('Contents', []):\n",
    "            key = obj['Key']\n",
    "            if key.endswith('.crc'):\n",
    "                print(f'Deleting {key}')\n",
    "                s3_client.delete_object(Bucket=bucket_name, Key=key)\n",
    "\n",
    "delete_crc(bucket, prefix_train)\n",
    "delete_crc(bucket, prefix_validation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
